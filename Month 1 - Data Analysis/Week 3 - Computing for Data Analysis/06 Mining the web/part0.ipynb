{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-5ae4e7b62e3457a9",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Part 0: Mining the web\n",
    "\n",
    "Perhaps the richest source of openly available data today is [the Web](http://www.computerhistory.org/revolution/networking/19/314)! In this lab, you'll explore some of the basic programming tools you need to scrape web data.\n",
    "\n",
    "> **Note.** The Vocareum platform runs in a cloud-based environment that limits what websites a program can connect to directly. Therefore, some (or possibly all) of the code below will **not** work. Therefore, we are making this notebook **optional** and are providing solutions inline.\n",
    ">\n",
    "> Even if you are using a home or local installation of Jupyter, you may encounter problems if you attempt to access a site too many times or too rapidly. That can happen if your internet service provider (ISP) or the target website detect your accesses as \"unusual\" and reject them. It's easy to imagine accidentally writing an infinite loop that tries to access a page and being seen from the other side as a malicious program. :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-8dc1f4f41590bfcc",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## The Requests module\n",
    "\n",
    "Python's [Requests module](http://requests.readthedocs.io/en/latest/user/quickstart/) to download a web page.\n",
    "\n",
    "For instance, here is a code fragment to download the [Georgia Tech](http://www.gatech.edu) home page and print the first 250 characters. You might also want to [view the source](http://www.computerhope.com/issues/ch000746.htm) of Georgia Tech's home page to get a nicely formatted view, and compare its output to what you see above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-9670461e96fd478a",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html lang=\"en\" dir=\"ltr\" \n",
      "  xmlns:content=\"http://purl.org/rss/1.0/modules/content/\"\n",
      "  xmlns:dc=\"http://purl.org/dc/terms/\"\n",
      "  xmlns:foaf=\"http://xmlns.com/foaf/0.1/\"\n",
      "  xmlns:og=\"http://ogp.me/ns#\"\n",
      "  xmlns:rdfs=\"http://www.w3.org/2000\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "response = requests.get('https://www.gatech.edu/')\n",
    "webpage = response.text  # or response.content for raw bytes\n",
    "\n",
    "print(webpage[0:250]) # Prints the first hundred characters only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 1.** Given the contents of the GT home page as above, write a function that returns a list of links (URLs) of the \"top stories\" on the page.\n",
    "\n",
    "For instance, on Friday, September 9, 2016, here was the front page:\n",
    "\n",
    "![www.gatech.edu as of Fri Sep 9, 2016](./www.gatech.edu--2016-09-09--annotated-medium.png)\n",
    "\n",
    "The top stories cycle through in the large image placeholder shown above. We want your function to return the list of URLs behind each of the \"Full Story\" links, highlighted in red. If no URLs can be found, the function should return an empty list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "get_top_stories",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "import re # Maybe you want to use a regular expression?\n",
    "\n",
    "def get_gt_top_stories(webpage_text):\n",
    "    \"\"\"Given the HTML text for the GT front page, returns a list\n",
    "    of the URLs of the top stories or an empty list if none are\n",
    "    found.\n",
    "    \"\"\"\n",
    "    # ANSWER:\n",
    "    pattern = '''<a class=\"slide-link\" href=\"(?P<url>[^\"]+)\"'''\n",
    "    return re.findall(pattern, webpage_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-6016c0d059ce46b6",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Links to GT's top stories: ['http://www.rh.gatech.edu/features/mending-broken-heart', 'https://www.news.gatech.edu/features/finding-fencing-rachel-wakefield']\n"
     ]
    }
   ],
   "source": [
    "top_stories = get_gt_top_stories(webpage)\n",
    "print(\"Links to GT's top stories:\", top_stories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-335e708786088da3",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## A more complex example\n",
    "\n",
    "Go to [Yelp!](http://www.yelp.com) and look up `ramen` in `Atlanta, GA`. Take note of the URL:\n",
    "\n",
    "![Yelp! search for ramen in ATL](./yelp-search-example.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-9beef10625b4a87b",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "This URL encodes what is known as an _HTTP \"get\"_ method (or request). It basically means a URL with two parts: a _command_ followed by one or more _arguments_. In this case, the command is everything up to and including the word `search`; the arguments are the rest, where individual arguments are separated by the `&` or `#`.\n",
    "\n",
    "> \"HTTP\" stands for \"HyperText Transport Protocol,\" which is a standardized set of communication protocols that allow _web clients_, like your web browser or your Python program, to communicate with _web servers_.\n",
    "\n",
    "In this next example, let's see how to build a \"get request\" with the `requests` module. It's pretty easy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-4b1c55e113ba9c09",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Downloading from: 'https://www.yelp.com/search?find_desc=ramen&find_loc=atlanta%2C+ga'\n",
      "\n",
      "==> Excerpt from this URL:\n",
      "\n",
      "<!DOCTYPE HTML>\n",
      "\n",
      "<!--[if lt IE 7 ]> <html xmlns:fb=\"http://www.facebook.com/2008/fbml\" class=\"ie6 ie\n",
      "\n"
     ]
    }
   ],
   "source": [
    "url_command = 'https://yelp.com/search'\n",
    "url_args = {'find_desc': \"ramen\",\n",
    "            'find_loc': \"atlanta, ga\"}\n",
    "response = requests.get (url_command, params=url_args, timeout=60)\n",
    "\n",
    "print (\"==> Downloading from: '%s'\" % response.url) # confirm URL\n",
    "print (\"\\n==> Excerpt from this URL:\\n\\n%s\\n\" % response.text[0:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 2.** Given a search topic, location, and a rank $k$, return the name of the $k$-th item of a Yelp! search. If there is no $k$-th item, return `None`.\n",
    "\n",
    "> The demo query above only gives you a website with the top 10 items, meaning you could only use it for $k \\leq 10$. Figure out how to modify it to solve the problem when $k > 10$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "yelp_find_item",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def find_yelp_item (topic, location, k):\n",
    "    \"\"\"Returns the k-th suggested item from Yelp! in Atlanta for the given topic.\"\"\"\n",
    "    # ANSWER:\n",
    "    import re\n",
    "    if k < 1: return None\n",
    "        \n",
    "    # Download page\n",
    "    url_command = 'https://yelp.com/search'\n",
    "    url_args = {'find_desc': topic,\n",
    "                'find_loc': location,\n",
    "                'start': k-1\n",
    "               }\n",
    "\n",
    "    response = requests.get (url_command, params=url_args)\n",
    "\n",
    "    if not response: return None\n",
    "    print('Downloaded from: {}'.format(response.url))\n",
    "    \n",
    "    # Look for the line containing the name of the k-th item\n",
    "    item_pattern = re.compile ('>{}<[^<]*<a[^>]*>(?P<item_name>.[^<]*)</a></h3>'.format(k))\n",
    "    item_matches = item_pattern.findall(response.text)\n",
    "\n",
    "    # Return the first match\n",
    "    if(len(item_matches) > 0):\n",
    "        return str(item_matches[0])\n",
    "    \n",
    "    # No matches, evidently\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "yelp_atl__test1",
     "locked": true,
     "points": 0,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert find_yelp_item('fried chicken', 'Atlanta, GA', -1) is None # Tests an invalid value for 'k'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a0a49b831193d0de",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "> Search queries on Yelp! don't always return the same answers, since the site is always changing! Also, your results might not match a query you do via your web browser (_why not?_). As such, you should manually check your answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "yelp_atl__test2",
     "locked": true,
     "points": 0,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded from: https://www.yelp.com/search?find_desc=fried+chicken&find_loc=Atlanta%2C+GA&start=0\n",
      "Gus’s World Famous Fried Chicken\n"
     ]
    }
   ],
   "source": [
    "item = find_yelp_item ('fried chicken', 'Atlanta, GA', 1)\n",
    "print (item)\n",
    "\n",
    "# The most likely answer on September 11, 2018:\n",
    "assert item in ['Gus’s World Famous <span class=\"highlighted\">Fried</span> <span class=\"highlighted\">Chicken</span>',\n",
    "                'Gus’s World Famous Fried Chicken']                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "yelp_atl__test3",
     "locked": true,
     "points": 0,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded from: https://www.yelp.com/search?find_desc=fried+chicken&find_loc=Atlanta%2C+GA&start=4\n",
      "Buttermilk Kitchen\n"
     ]
    }
   ],
   "source": [
    "item = find_yelp_item ('fried chicken', 'Atlanta, GA', 5)\n",
    "print (item)\n",
    "\n",
    "# The most likely answer on September 11, 2018:\n",
    "assert item == 'Buttermilk Kitchen'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "yelp_atl__test4",
     "locked": true,
     "points": 0,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded from: https://www.yelp.com/search?find_desc=fried+chicken&find_loc=Atlanta%2C+GA&start=9\n",
      "ChiChop\n"
     ]
    }
   ],
   "source": [
    "item = find_yelp_item('fried chicken', 'Atlanta, GA', 10)\n",
    "print(item)\n",
    "\n",
    "# Most likely correct answer as of February 15, 2019:\n",
    "assert item == 'ChiChop'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-79798e6a4a127482",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "One issue with the above exercises is that they treat HTML as a flat string, whereas the document is at least semi-structured. Moreover, web pages are such a common source of data today that you would expect better tools for processing them. Indeed, such tools exist! The next part of this assignment, Part 1, walks you through one such tool. So, head there when you are ready!"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": [],
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
